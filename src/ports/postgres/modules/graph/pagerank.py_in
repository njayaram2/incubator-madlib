# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# PageRank

# Please refer to the pagerank.sql_in file for the documentation

"""
@file pagerank.py_in

@namespace graph
"""

import plpy
from utilities.control import MinWarning
from utilities.utilities import _assert
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import unique_string
from utilities.control import IterationController2S
from graph_utils import *

m4_changequote(`<!', `!>')

def validate_pagerank_args(vertex_table, vertex_id, edge_table, edge_params,
        out_table, damping_factor, max_iter, threshold, module_name):
    """
    Function to validate input parameters for PageRank
    """
    validate_graph_coding(vertex_table, vertex_id, edge_table, edge_params,
        out_table, module_name)
    _assert(isinstance(damping_factor, float),
        """PageRank: Damping factor {0} has to be a float.""".format(damping_factor))
    _assert(isinstance(max_iter, int),
        """PageRank: Max_iter {0} has to be a int.""".format(max_iter))
    _assert(isinstance(threshold, float),
        """PageRank: Threshold {0} has to be a float.""".format(threshold))

def pagerank(schema_madlib, vertex_table, vertex_id, edge_table, edge_args,
    out_table, damping_factor, max_iter, threshold, **kwargs):
    """
    Function that computes the PageRank

    Args:
        @param vertex_table
        @param vertex_id
        @param edge_table
        @param source_vertex
        @param dest_vertex
        @param out_table
        @param damping_factor
        @param max_iter
        @param threshold
    """
    old_msg_level = plpy.execute("""
                                  SELECT setting
                                  FROM pg_settings
                                  WHERE name='client_min_messages'
                                  """)[0]['setting']
    plpy.execute('SET client_min_messages TO warning')
    params_types = {'src': str, 'dest': str}
    default_args = {'src': 'src', 'dest': 'dest'}
    edge_params = extract_keyvalue_params(edge_args, params_types, default_args)
    validate_pagerank_args(vertex_table, vertex_id, edge_table, edge_params,
        out_table, damping_factor, max_iter, threshold, 'PageRank')
    src = edge_params["src"]
    dest = edge_params["dest"]

    input_table = unique_string(desp='input_table')
    inedges = unique_string(desp='inedges')
    outdegrees = unique_string(desp='outdegrees')
    unique_vertex_id = unique_string(desp='rid')

    ## Step 1: Create a copy of the input table, adding some new columns:
    # Step 1.1: First simulate vertex IDs starting from 0
    vertex_distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
        <!"DISTRIBUTED BY ({0})".format(unique_vertex_id)!>)
    vertex_temp_table = unique_string(desp='vertex')
    plpy.execute("""DROP TABLE IF EXISTS {vertex_temp_table};
        CREATE TEMP TABLE {vertex_temp_table} AS
        SELECT (ROW_NUMBER() OVER ())-1 AS {unique_vertex_id},
                {vertex_id}
        FROM {vertex_table}
        {vertex_distribution}
        """.format(**locals()))
    # GPDB and HAWQ have distributed by clauses to help them with indexing.
    # For Postgres we add the indices manually.
    sql_index = m4_ifdef(<!__POSTGRESQL__!>,
        <!"""CREATE INDEX ON {vertex_temp_table} ({unique_vertex_id});
        """.format(**locals())!>,
        <!''!>)
    plpy.execute(sql_index)

    # Step 1.2: Create a meta-table, like an adjacency list, where the incoming
    # edges for all vertices, along with the out-degree of the "source" vertices
    # of those incoming edges is captured.
    distribution = m4_ifdef(<!__POSTGRESQL__!>, <!''!>,
        <!"DISTRIBUTED BY ({0})".format(vertex_id)!>)
    plpy.execute("""
        DROP TABLE IF EXISTS {input_table};
        CREATE TABLE {input_table}(
        {vertex_id} INT,
        {inedges} INT[],
        {outdegrees} INT[]
        )
        {distribution}
        """.format(**locals()))
    # GPDB and HAWQ have distributed by clauses to help them with indexing.
    # For Postgres we add the indices manually.
    sql_index = m4_ifdef(<!__POSTGRESQL__!>,
        <!"""CREATE INDEX ON {input_table} ({vertex_id});
        """.format(**locals())!>,
        <!''!>)
    plpy.execute(sql_index)

    t_sub = unique_string(desp='subquery')
    out_cnts = unique_string(desp='out_cnts')
    out_cnts_src = unique_string(desp='id')
    out_cnts_cnt = unique_string(desp='cnt')
    v1 = unique_string(desp='v1')
    v2 = unique_string(desp='v2')
    # Compute the out-degree of every node in the graph.
    plpy.execute("""
        DROP TABLE IF EXISTS {out_cnts};
        CREATE TEMP TABLE {out_cnts} AS
        SELECT {t_sub}.{out_cnts_src}, {t_sub}.{out_cnts_cnt}
        FROM (
            SELECT {edge_table}.{src}, {v1}.{unique_vertex_id} AS {out_cnts_src}, COUNT({v2}.{unique_vertex_id}) AS {out_cnts_cnt}
            FROM {edge_table}, {vertex_temp_table} AS {v1}, {vertex_temp_table} AS {v2}
            WHERE {edge_table}.{src}={v1}.{vertex_id} AND {edge_table}.{dest}={v2}.{vertex_id}
            GROUP BY {edge_table}.{src}, {v1}.{unique_vertex_id}
        ) {t_sub}
         """.format(**locals()))
    # Use the unique_vertex_id instead of the original vertex_id while creating
    # the table. The input_table contains three columns: vertex_id, inedges, outedges
    # "inedges" consists of an array of nodes that have an edge TO vertex_id, while
    # "outedges" is an array containing the out-degree of all the nodes listed in "inedges".
    # The dimensions of inedges and outedges are hence the same.
    t_sub2 = unique_string(desp='subquery2')
    plpy.execute("""
        INSERT INTO {input_table}
        SELECT {t_sub2}.{unique_vertex_id} AS {vertex_id},
                {t_sub2}.{inedges}, {t_sub2}.{outdegrees}
        FROM (
            SELECT {edge_table}.{dest}, {v2}.{unique_vertex_id},
                array_agg({t_sub}.{out_cnts_src}) AS {inedges},
                array_agg({t_sub}.{out_cnts_cnt}) AS {outdegrees}
            FROM {edge_table}, {vertex_temp_table} AS {v1}, {vertex_temp_table} AS {v2},
            (
                SELECT {out_cnts_src}, {out_cnts_cnt}
                FROM {out_cnts}
            ) {t_sub}
            WHERE {t_sub}.{out_cnts_src}={v1}.{unique_vertex_id} AND
                {v1}.{vertex_id}={edge_table}.{src} AND
                {v2}.{vertex_id}={edge_table}.{dest}
            GROUP BY {edge_table}.{dest}, {v2}.{unique_vertex_id}
        ) {t_sub2}
    """.format(**locals()))

    ## There might be nodes in the graph that have no incoming edges at all,
    ## which will not be represented in {input_table}. Add entries for such
    ## nodes with empty arrays for {inedges} and {outdegrees}
    plpy.execute("""
        INSERT INTO {input_table}
        SELECT {vertex_temp_table}.{unique_vertex_id} AS {vertex_id}
        FROM {vertex_temp_table}
        WHERE {vertex_temp_table}.{unique_vertex_id} NOT IN (
            SELECT {input_table}.{vertex_id}
            FROM {input_table})
        """.format(**locals()))

    # The unique_vertex_id starts from 0, thus adding 1 to the largest
    # unique_vertex_id to find the total number of vertices in the graph.
    nvertices = plpy.execute("""
            SELECT MAX({0}) AS max_id
            FROM {1}
        """.format(unique_vertex_id, vertex_temp_table))[0]["max_id"] + 1
    plpy.execute("""DROP TABLE {0}""".format(out_cnts))

    ## Step 2: Compute PageRank.
    rel_args = unique_string(desp='rel_args')
    plpy.execute("""
            DROP TABLE IF EXISTS {rel_args};
            CREATE TEMP TABLE {rel_args} AS
            SELECT {damping_factor}::double precision AS damping_factor,
                   {nvertices}::integer AS nvertices,
                   {max_iter}::integer AS max_iter,
                   {threshold}::double precision AS threshold
        """.format(**locals()))
    rel_state = unique_string(desp='rel_state')
    iterationCtrl = IterationController2S(
        rel_args = rel_args,
        rel_state = rel_state,
        stateType = "DOUBLE PRECISION[]",
        truncAfterIteration = False,
        schema_madlib = schema_madlib,
        rel_source = input_table,
        initialize_state=True,
        inedges = inedges,
        outdegrees = outdegrees,
        vertex = vertex_id,
        **kwargs)
    with iterationCtrl as it:
        it.iteration = 0
        while True:
            it.update("""
                SELECT
                    {schema_madlib}.__compute_pagerank(
                        (_src.{vertex})::integer,
                        (_src.{inedges})::integer[],
                        (_src.{outdegrees})::integer[],
                        m4_ifdef(<!__HAWQ__!>, <!{{__state__}}!>,<!
                        (SELECT _state FROM {rel_state}
                            WHERE _iteration = {iteration})!>),
                        (_args.damping_factor)::double precision,
                        (_args.nvertices)::integer)
                FROM {rel_source} AS _src, {rel_args} AS _args
                """)
            if it.iteration > 1 and it.test("""
                {iteration} > _args.max_iter OR
                {schema_madlib}.test_pagerank_convergence(
                    _state_previous, _state_current, _args.threshold)
                """):
                break

    iterations = iterationCtrl.iteration
    with MinWarning("info"):
        plpy.debug("Took {0} iterations to converge! ".format(iterations))

    ## Step 3: Write PageRank scores to output table.
    plpy.execute("""CREATE TABLE {out_table} AS
            SELECT {vertex_id} AS {vertex_id}, {t_sub}.pagerank AS pagerank
            FROM {vertex_temp_table}
            INNER JOIN (
                WITH pivoted_array AS(
                    SELECT unnest(_state)
                    FROM {rel_state}
                    WHERE _iteration={iterations}
                )
                SELECT (ROW_NUMBER() OVER())-1 AS {unique_vertex_id}, unnest AS pagerank
                FROM pivoted_array) {t_sub} ON {t_sub}.{unique_vertex_id}={vertex_temp_table}.{unique_vertex_id}
            """.format(**locals()))

    ## Step 4: Cleanup
    plpy.execute("""
        DROP TABLE IF EXISTS {0};
        DROP TABLE IF EXISTS {1};
        DROP TABLE IF EXISTS {2};
        DROP TABLE IF EXISTS {3};
        """.format(input_table, rel_args, rel_state, vertex_temp_table))
    plpy.execute("SET client_min_messages TO %s" % old_msg_level)

def pagerank_help(schema_madlib, message, **kwargs):
    """
    Help function for pagerank

    Args:
        @param schema_madlib
        @param message: string, Help message string
        @param kwargs

    Returns:
        String. Help/usage information
    """
    if message is not None and \
            message.lower() in ("usage", "help", "?"):
        help_string = "Get from method below"
        help_string = get_graph_usage(schema_madlib, 'PageRank',
            """out_table       TEXT, -- Name of the output table for PageRank
damping_factor, DOUBLE PRECISION, -- Damping factor in random surfer model (DEFAULT = 0.85)
max_iter,       INTEGER, -- Maximum iteration number (DEFAULT = 100)
threshold       DOUBLE PRECISION -- Stopping criteria (DEFAULT = 1e-5)
""")
    else:
        if message is not None and \
                message.lower() in ("example", "examples"):
            help_string = """
----------------------------------------------------------------------------
                                EXAMPLES
----------------------------------------------------------------------------
-- Create a graph, represented as vertex and edge tables.
DROP TABLE IF EXISTS vertex, edge;
CREATE TABLE vertex(
        id INTEGER
        );
CREATE TABLE edge(
        src INTEGER,
        dest INTEGER
        );
INSERT INTO vertex VALUES
(0),
(1),
(2),
(3),
(4),
(5),
(6);
INSERT INTO edge VALUES
(0, 1),
(0, 2),
(0, 4),
(1, 2),
(1, 3),
(2, 3),
(2, 5),
(2, 6),
(3, 0),
(4, 0),
(5, 6),
(6, 3);

-- Compute the PageRank:
DROP TABLE IF EXISTS pagerank_out;
SELECT madlib.pagerank(
             'vertex',             -- Vertex table
             'id',                 -- Vertix id column
             'edge',               -- Edge table
             'src=src, dest=dest', -- Comma delimted string of edge arguments
             'pagerank_out')       -- Output table of PageRank

-- View the PageRank of all vertices, sorted by their scores.
SELECT * FROM pagerank_out ORDER BY pagerank desc;
"""
        else:
            help_string = """
----------------------------------------------------------------------------
                                SUMMARY
----------------------------------------------------------------------------
Given a directed graph, pagerank algorithm finds the PageRank score of all
the vertices in the graph.
--
For an overview on usage, run:
SELECT {schema_madlib}.pagerank('usage');

For some examples, run:
SELECT {schema_madlib}.pagerank('example')
--
"""

    return help_string.format(schema_madlib=schema_madlib)
# ---------------------------------------------------------------------
